{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4d388c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "import timm\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from tqdm import tqdm,trange\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score  \n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e902d3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    data_dir = \"D:\\\\Leko\\\\medical_model\\\\task1\\\\dataset\\\\images\"\n",
    "    label_csv = \"D:\\\\Leko\\\\medical_model\\\\task1\\\\dataset\\\\labels.csv\"\n",
    "    img_size = 224\n",
    "    batch_size = 32\n",
    "    epochs = 20\n",
    "    lr = 5e-5\n",
    "    num_workers = 0\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model_name = \"convnext_tiny_in22ft1k\"\n",
    "    save_dir = \"./output\"\n",
    "    #n_splits = 5\n",
    "    seed = 42\n",
    "\n",
    "torch.manual_seed(Config.seed)\n",
    "os.makedirs(Config.save_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d05810",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TumorDataset(Dataset):\n",
    "    def __init__(self, df, img_dir, train=True):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.img_dir = img_dir\n",
    "        self.train = train\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img_path = os.path.join(self.img_dir, row['filename'])\n",
    "        image = np.array(Image.open(img_path).convert('RGB'))\n",
    "        label = int(row['label'])\n",
    "\n",
    "        if self.train:\n",
    "            transform = get_transforms(train=True, is_tumor=(label == 1))\n",
    "        else:\n",
    "            transform = get_transforms(train=False)\n",
    "\n",
    "        image = transform(image=image)['image']\n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ba5b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CutMixCollator:#Ê∂àËûçÂÆûÈ™åËÆ∞ÂæóÂä†\n",
    "    def __init__(self, beta=1.0, prob=0.5):\n",
    "        self.beta = beta\n",
    "        self.prob = prob\n",
    "\n",
    "    def __call__(self, batch):\n",
    "        images, labels = zip(*batch)\n",
    "        images = torch.stack(images)\n",
    "        labels = torch.tensor(labels).float().view(-1, 1)  \n",
    "\n",
    "        if np.random.rand() > self.prob:\n",
    "            return images, labels\n",
    "\n",
    "        lam = np.random.beta(self.beta, self.beta)\n",
    "        batch_size = images.size(0)\n",
    "        index = torch.randperm(batch_size)\n",
    "\n",
    "        mixed_images = lam * images + (1 - lam) * images[index]\n",
    "        mixed_labels = lam * labels + (1 - lam) * labels[index]\n",
    "        return mixed_images, mixed_labels\n",
    "\n",
    "\n",
    "\n",
    "class MixUpCollator:\n",
    "    def __init__(self, alpha=0.4, prob=0.5):\n",
    "        self.alpha = alpha\n",
    "        self.prob = prob\n",
    "\n",
    "    def __call__(self, batch):\n",
    "        images, labels = zip(*batch)\n",
    "        images = torch.stack(images)\n",
    "        labels = torch.tensor(labels).float().view(-1, 1)\n",
    "\n",
    "\n",
    "        if np.random.rand() > self.prob:\n",
    "            return images, labels\n",
    "\n",
    "        lam = np.random.beta(self.alpha, self.alpha)\n",
    "        index = torch.randperm(images.size(0))\n",
    "        mixed_images = lam * images + (1 - lam) * images[index]\n",
    "        labels = lam * labels + (1 - lam) * labels[index]\n",
    "        return mixed_images, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d795a5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transforms(train=True, is_tumor=False):\n",
    "    if train:\n",
    "        base = [\n",
    "            A.Resize(Config.img_size, Config.img_size),\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "        ]\n",
    "        if is_tumor:\n",
    "            base += [\n",
    "                A.RandomBrightnessContrast(p=0.5),\n",
    "                A.ElasticTransform(alpha=1, sigma=50, alpha_affine=30, p=0.3),\n",
    "                A.CoarseDropout(p=0.3)\n",
    "            ]\n",
    "        base += [\n",
    "            A.Normalize(mean=(0.485, 0.456, 0.406),\n",
    "                        std=(0.229, 0.224, 0.225)),\n",
    "            ToTensorV2()\n",
    "        ]\n",
    "        return A.Compose(base)\n",
    "    else:\n",
    "        return A.Compose([\n",
    "            A.Resize(Config.img_size, Config.img_size),\n",
    "            A.Normalize(mean=(0.485, 0.456, 0.406),\n",
    "                        std=(0.229, 0.224, 0.225)),\n",
    "            ToTensorV2()\n",
    "        ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23bfa702",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TumorClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.backbone = timm.create_model(Config.model_name, pretrained=True, num_classes=0, global_pool=\"\")\n",
    "        in_features = self.backbone.num_features\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Flatten(),\n",
    "            nn.BatchNorm1d(in_features),\n",
    "            nn.Dropout(0.6), #0.5ËøáÊãüÂêà‰∫Ü\n",
    "            nn.Linear(in_features, 1)\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.backbone.forward_features(x)\n",
    "        return self.classifier(features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0805e77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.25, gamma=2.0):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        BCE_loss = nn.BCEWithLogitsLoss(reduction='none')(inputs, targets)\n",
    "        pt = torch.exp(-BCE_loss)\n",
    "        focal_loss = self.alpha * (1 - pt) ** self.gamma * BCE_loss\n",
    "        return focal_loss.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15d5f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, loader, optimizer, criterion, scaler):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for images, labels in tqdm(loader):\n",
    "        images = images.to(Config.device)\n",
    "        labels = labels.to(Config.device)  \n",
    "        optimizer.zero_grad()\n",
    "        with autocast():\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538ac11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    preds, targets = [], []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images = images.to(Config.device)\n",
    "            labels = labels.float().unsqueeze(1).to(Config.device)\n",
    "            with autocast():\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "            probs = torch.sigmoid(outputs)\n",
    "            preds.extend(probs.cpu().numpy())\n",
    "            targets.extend(labels.cpu().numpy())\n",
    "    return total_loss / len(loader), np.array(preds), np.array(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72cc4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, delta=0):\n",
    "        self.patience = patience\n",
    "        self.delta = delta\n",
    "        self.best_score = None\n",
    "        self.counter = 0\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_score):\n",
    "        if self.best_score is None:\n",
    "            self.best_score = val_score\n",
    "        elif val_score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = val_score\n",
    "            self.counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a336c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "full_df = pd.read_csv(Config.label_csv)\n",
    "\n",
    "train_df, val_df = train_test_split(\n",
    "    full_df,\n",
    "    test_size=0.2,\n",
    "    stratify=full_df['label'],\n",
    "    random_state=Config.seed\n",
    ")\n",
    "\n",
    "print(f\"ËÆ≠ÁªÉÈõÜÁ±ªÂà´ÂàÜÂ∏ÉÔºö\\n{train_df['label'].value_counts()}\")\n",
    "print(f\"È™åËØÅÈõÜÁ±ªÂà´ÂàÜÂ∏ÉÔºö\\n{val_df['label'].value_counts()}\")\n",
    "\n",
    "use_mix_mode = \"cutmix\"  # Êàñ \"mixup\", \"none\"\n",
    "if use_mix_mode == \"cutmix\":\n",
    "    collate_fn = CutMixCollator(beta=1.0, prob=0.3)\n",
    "elif use_mix_mode == \"mixup\":\n",
    "    collate_fn = MixUpCollator(alpha=0.4, prob=0.5)\n",
    "else:\n",
    "    collate_fn = None\n",
    "\n",
    "class_counts = train_df['label'].value_counts().sort_index().values\n",
    "class_weights = 1. / torch.tensor(class_counts, dtype=torch.float)\n",
    "sample_weights = train_df['label'].map({0: class_weights[0], 1: class_weights[1]}).astype('float32').values\n",
    "sampler = WeightedRandomSampler(sample_weights, len(sample_weights))\n",
    "\n",
    "train_dataset = TumorDataset(train_df, Config.data_dir, train=True)\n",
    "val_dataset = TumorDataset(val_df, Config.data_dir, train=False)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=Config.batch_size, sampler=sampler, num_workers=Config.num_workers, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=Config.batch_size, shuffle=False, num_workers=Config.num_workers)\n",
    "\n",
    "print(\"ÂàùÂßãÂåñÊ®°Âûã‰∏≠...\")\n",
    "model = TumorClassifier().to(Config.device)\n",
    "print(\"Ê®°ÂûãÂàùÂßãÂåñÂÆåÊàê\")\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=Config.lr, weight_decay=1e-4)\n",
    "criterion = FocalLoss(alpha=0.75, gamma=1.5)\n",
    "early_stopper = EarlyStopping(patience=5)\n",
    "scaler = GradScaler()\n",
    "\n",
    "history = {'train_loss': [], 'val_loss': [], 'val_auc': [], 'val_f1': []}\n",
    "best_auc = 0\n",
    "\n",
    "train_labels = train_df['label']\n",
    "print(f\"ÂΩìÂâçËÆ≠ÁªÉÈõÜÂõæÂÉèÂàÜÂ∏ÉÔºöÊ≠£Â∏∏Á±ª {(train_labels == 0).sum()}ÔºåËÇøÁò§Á±ª {(train_labels == 1).sum()}\")\n",
    "\n",
    "for epoch in range(Config.epochs):\n",
    "    print(f\"\\nüìò Epoch {epoch+1}/{Config.epochs}\")\n",
    "    train_loss = train_one_epoch(model, train_loader, optimizer, criterion, scaler)\n",
    "    val_loss, preds, targets = evaluate(model, val_loader, criterion)\n",
    "    val_auc = roc_auc_score(targets, preds)\n",
    "\n",
    "    # ÈªòËÆ§ F1 Âíå ÊúÄ‰Ω≥ F1 ÈòàÂÄºÊêúÁ¥¢\n",
    "    preds_bin_default = (preds >= 0.5).astype(int)\n",
    "    val_f1_default = f1_score(targets, preds_bin_default)\n",
    "\n",
    "    best_f1, best_thresh = 0, 0.5\n",
    "    for t in np.arange(0.1, 0.9, 0.01):\n",
    "        f1 = f1_score(targets, (preds >= t).astype(int))\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_thresh = t\n",
    "    preds_bin = (preds >= best_thresh).astype(int)\n",
    "\n",
    "    print(f\"È¢ÑÊµã‰∏∫ËÇøÁò§Á±ª(1)ÁöÑÊï∞Èáè: {(preds_bin == 1).sum()} / {len(preds_bin)}\")\n",
    "    print(f\"Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | AUC: {val_auc:.4f}\")\n",
    "    print(f\"F1@0.50: {val_f1_default:.4f} | Best F1@{best_thresh:.2f}: {best_f1:.4f}\")\n",
    "    print(f\"Accuracy: {accuracy_score(targets, preds_bin):.4f}\")\n",
    "\n",
    "    cm = confusion_matrix(targets, preds_bin)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    print(f\"Sensitivity (Recall for tumor): {tp / (tp + fn + 1e-8):.4f}\")\n",
    "    print(f\"Specificity (Recall for normal): {tn / (tn + fp + 1e-8):.4f}\")\n",
    "\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_auc'].append(val_auc)\n",
    "    history['val_f1'].append(best_f1)\n",
    "\n",
    "    if val_auc > best_auc:\n",
    "        best_auc = val_auc\n",
    "        torch.save(model.state_dict(), os.path.join(Config.save_dir, \"best_model.pth\"))\n",
    "        with open(os.path.join(Config.save_dir, \"best_thresh.txt\"), 'w') as f:\n",
    "            f.write(f\"{best_thresh:.4f}\")\n",
    "        print(\"Best model saved.\")\n",
    "\n",
    "    if early_stopper(val_auc):\n",
    "        print(\"Early stopping triggered.\")\n",
    "        break\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(history['train_loss'], label='Train')\n",
    "plt.plot(history['val_loss'], label='Val')\n",
    "plt.title(\"Loss\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(history['val_auc'])\n",
    "plt.title(\"Val AUC\")\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(history['val_f1'])\n",
    "plt.title(\"Best F1\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(4, 4))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"Normal\", \"Tumor\"], yticklabels=[\"Normal\", \"Tumor\"])\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "val_df = val_df.copy()\n",
    "val_df['pred_prob'] = preds\n",
    "val_df['pred_label'] = preds_bin\n",
    "val_df.to_csv(os.path.join(Config.save_dir, \"val_predictions.csv\"), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9f51f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as T\n",
    "import matplotlib\n",
    "\n",
    "\n",
    "matplotlib.rcParams['font.family'] = 'Microsoft YaHei'\n",
    "plt.rcParams['axes.unicode_minus'] = False  \n",
    "\n",
    "# Âä†ËΩΩÊ®°ÂûãÁªìÊûÑ\n",
    "model = TumorClassifier().to(Config.device)\n",
    "model.load_state_dict(torch.load(\"D:\\\\Leko\\\\medical_model\\\\task1\\\\output\\\\best_model.pth\"))\n",
    "model.eval()\n",
    "\n",
    "# Âä†ËΩΩ‰Ω†ËÆ≠ÁªÉÊó∂ÁöÑÂõæÂÉèÈ¢ÑÂ§ÑÁêÜ\n",
    "infer_transform = get_transforms(train=False)\n",
    "\n",
    "def predict_image(image_path):\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    image_np = np.array(image)\n",
    "    \n",
    "    # Apply transform\n",
    "    transformed = infer_transform(image=image_np)\n",
    "    input_tensor = transformed['image'].unsqueeze(0).to(Config.device)\n",
    "\n",
    "    # Predict\n",
    "    with torch.no_grad():\n",
    "        output = model(input_tensor)\n",
    "        prob = torch.sigmoid(output).item()\n",
    "        label = 1 if prob >= 0.5 else 0\n",
    "\n",
    "    # ÂèØËßÜÂåñ\n",
    "    plt.imshow(image_np)\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"È¢ÑÊµãÊ†áÁ≠æ: {'ËÇøÁò§' if label==1 else 'Ê≠£Â∏∏'}\\nÈ¢ÑÊµãÊ¶ÇÁéá: {prob:.4f}\")\n",
    "    plt.show()\n",
    "\n",
    "predict_image(\"D:\\\\Leko\\\\test3.jpg\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multi_task",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
